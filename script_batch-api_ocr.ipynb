{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T08:06:24.306352Z",
     "start_time": "2025-01-05T08:06:24.280776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "from PIL import Image\n",
    "from app.ocr_functions import image_pil_to_data_url\n",
    "from pydantic import BaseModel\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "credential = DefaultAzureCredential()\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import requests\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import (\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    "    TextContentItem,\n",
    "    ImageContentItem,\n",
    "    ImageUrl,\n",
    "    ImageDetailLevel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"Your are an OCR client using your Vision Capabilities to perform your response and provide a clean and structured text without any notes.\"\n",
    "user_prompt = \"\"\"extract the text from the image and provide a clean and structured text. \n",
    "                your output format must be in markdown format, with the text extracted from the image. \n",
    "                output will be  in 'markdown' text with markdown rules like titles,headings,etc, nothing else.\n",
    "                \n",
    "                NOTES:\n",
    "                1) in the output, don't write ```markdown``` or ```md``` or any other code block.\n",
    "                \n",
    "                2) don't add any notes from you, just out the text extracted from the image. without any additions\n",
    "                \n",
    "                3) Warning! Don't Add Notice section to tell me that the text is not clear or any other notes.\n",
    "\n",
    "                4) even if the text is not clear, try to extract as much as possible, and don't provide any extra notes.\n",
    "                \n",
    "                5) output the raw text extracted from the image as well. this text will be used for embedding purposes. So, Make sure that you don't lose any essential layouts when extract as raw text.\n",
    "                \n",
    "                6) Extract the text in the language it is written in the image.\n",
    "                \n",
    "                7) I will provide you multiple images, extract the text from all the images and provide the output in the same format.\n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "def generate_request(path, image_url):\n",
    "    \"\"\"\n",
    "    Generates a request for the Batch API to extract text from an image.\n",
    "\n",
    "    Args:\n",
    "        path (str): The absolute file path of the image (used as custom_id).\n",
    "        image_url (str): The URL or base64-encoded data of the image.\n",
    "        system_prompt (str): The system prompt for the task.\n",
    "        user_prompt (str): The user prompt for the task.\n",
    "\n",
    "    Returns:\n",
    "        dict: A request in the required JSON format.\n",
    "    \"\"\"\n",
    "    request = {\n",
    "        \"custom_id\": path,  # Use the absolute file path as custom_id\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"archivai-gpt-4o-batch\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": user_prompt\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": image_url\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"response_format\": {\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": {\n",
    "                    \"name\": \"TextExtractionResponse\",\n",
    "                    \"strict\": True,\n",
    "                    \"schema\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"markdown_text\": {\n",
    "                                \"type\": \"string\"\n",
    "                            },\n",
    "                            \"raw_text\": {\n",
    "                                \"type\": \"string\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"markdown_text\", \"raw_text\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Requests from Resume Folder Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_folder = \"tobacco-dataset\\Resume\"\n",
    "output_file = \"batch_requests.jsonl\"\n",
    "\n",
    "with open(output_file, \"w\") as jsonl_file:\n",
    "    for root, dirs, files in os.walk(resume_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".png\") or file.endswith(\".jpg\"):\n",
    "                image_path = os.path.join(root, file)\n",
    "                image = Image.open(image_path)\n",
    "                image_url = image_pil_to_data_url(image)\n",
    "                request = generate_request(image_path, image_url)\n",
    "                jsonl_file.write(json.dumps(request) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Requests from all dataset using data-url\n",
    "Note: This is not good approach because the request file will be large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_floder = \"tobacco-dataset\"\n",
    "\n",
    "output_file = \"batch_requests.jsonl\"\n",
    "\n",
    "with open(output_file, 'w') as jsonl_file:\n",
    "    for folder in os.listdir(root_floder):\n",
    "        folder_path = os.path.join(root_floder, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for image in os.listdir(folder_path):\n",
    "                image_path = os.path.join(folder_path, image)\n",
    "                with Image.open(image_path) as img:\n",
    "                    image_url = image_pil_to_data_url(img)\n",
    "                    request = generate_request(image_path, image_url)\n",
    "                    jsonl_file.write(json.dumps(request) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Requests from dataset images-url\n",
    "This is the best approachc to reduce the size of requests.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the BlobServiceClient\n",
    "keyvault_name = \"vaultarchivai\"\n",
    "kv_uri = f\"https://{keyvault_name}.vault.azure.net\"\n",
    "keys_client = SecretClient(vault_url=kv_uri, credential=credential)\n",
    "\n",
    "connection_string = keys_client.get_secret(\"blob-connection-string\").value\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "\n",
    "# Specify the container and directory\n",
    "container_name = \"tobacco-dataset\"\n",
    "directory_name = \"Resume\"\n",
    "\n",
    "# Get the container client\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "# List all blobs in the specified directory\n",
    "blob_list = container_client.list_blobs()\n",
    "filterd_blob_list = [blob for blob in blob_list if not blob.name.startswith(directory_name)]\n",
    "# Generate URLs for each blob\n",
    "blob_urls = []\n",
    "for blob in filterd_blob_list:\n",
    "    blob_path = f\"{blob.name}\"\n",
    "    blob_url = f\"https://{blob_service_client.account_name}.blob.core.windows.net/{container_name}/{blob.name}\"\n",
    "    tuple_obj = (blob_path, blob_url)\n",
    "    blob_urls.append(tuple_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"batch_requests_all-e-Resume.jsonl\"\n",
    "with open(output_file, \"w\") as jsonl_file:\n",
    "    for blob_path, blob_url in blob_urls:\n",
    "        request = generate_request(blob_path, blob_url)\n",
    "        jsonl_file.write(json.dumps(request) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR Invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyvault_name = \"vaultarchivai\"\n",
    "kv_uri = f\"https://{keyvault_name}.vault.azure.net\"\n",
    "keys_client = SecretClient(vault_url=kv_uri, credential=credential)\n",
    "\n",
    "# Authenticate to Azure OpenAI\n",
    "api_base = keys_client.get_secret(\"archivai-openai-base\").value\n",
    "api_key= keys_client.get_secret(\"archivaigpt4-key\").value\n",
    "deployment_name = 'archivaigpt4'\n",
    "api_version = '2024-08-01-preview'\n",
    "client = AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    api_version=api_version,\n",
    "    base_url=f\"{api_base}/openai/deployments/{deployment_name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Page(BaseModel):\n",
    "    markdown_text: str\n",
    "    raw_text: str\n",
    "def ocr_invoke(client, system_prompt, user_prompt, url):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": user_prompt\n",
    "                },\n",
    "                # Add one dict per image url\n",
    "                (\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": url}\n",
    "                    }\n",
    "                )\n",
    "            ],\n",
    "        }]\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "    model=deployment_name,\n",
    "    messages=messages,\n",
    "    response_format=Page,\n",
    "    )\n",
    "    return completion.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://filstrg.blob.core.windows.net/tobacco-dataset/ADVE/86122854.jpg\"\n",
    "result = ocr_invoke(system_prompt, user_prompt, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Newport Pleasure!\\n\\n**FIRE IT UP!**\\n\\n---\\n\\n_Canoe Trip._\\nGM 2 x 60\\nMarch-April 1999\\n\\n---\\n\\n86122854'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.dict()['markdown_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload folders to blob container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading News files: 100%|██████████| 189/189 [04:33<00:00,  1.45s/it]\n",
      "Uploading Note files: 100%|██████████| 202/202 [03:25<00:00,  1.02s/it]\n",
      "Uploading Report files: 100%|██████████| 266/266 [05:11<00:00,  1.17s/it]\n",
      "Uploading scientific files: 100%|██████████| 262/262 [10:51<00:00,  2.49s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Upload folders to blob container\n",
    "container_name = \"tobacco-dataset\"\n",
    "root_folder = \"tobacco-dataset\"\n",
    "sub_folders = ['News','Note', 'Report', 'scientific']\n",
    "\n",
    "for folder in sub_folders:\n",
    "    folder_path = os.path.join(root_folder, folder)\n",
    "    files = os.listdir(folder_path)\n",
    "    for file in tqdm(files, desc=f'Uploading {folder} files'):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        blob_path = f\"{folder}/{file}\"\n",
    "        with open(file_path, \"rb\") as data:\n",
    "            container_client.upload_blob(name=blob_path, data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge 2 requests jsonl files: the Resume Requests, and the rest of folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 2 jsonl files\n",
    "file1 = \"resume_batch_requests.jsonl\"\n",
    "file2 = \"batch_requests_all-e-Resume.jsonl\"\n",
    "\n",
    "with open(file1, \"r\") as file:\n",
    "    data1 = file.read()\n",
    "\n",
    "with open(file2, \"r\") as file:\n",
    "    data2 = file.read()\n",
    "\n",
    "merged_data = data1 + data2 \n",
    "with open(\"batch_requests_all.jsonl\", \"w\") as file:\n",
    "    file.write(merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge 2 rersponses jsonl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 2 jsonl files\n",
    "file1 = \"resume.jsonl\"\n",
    "file2 = \"file-128233ea-7ab4-4a23-9c98-47112cc6e3e9.jsonl\"\n",
    "\n",
    "with open(file1, \"r\") as file:\n",
    "    data1 = file.read()\n",
    "\n",
    "with open(file2, \"r\") as file:\n",
    "    data2 = file.read()\n",
    "\n",
    "merged_data = data1 + data2 \n",
    "with open(\"batch_responses_all.jsonl\", \"w\") as file:\n",
    "    file.write(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "file1 = \"batch_requests_all.jsonl\"\n",
    "file2 = \"batch_responses_all.jsonl\"\n",
    "# Find custom_ids that are in file1 but not in file2\n",
    "with jsonlines.open(file1) as reader:\n",
    "    requests = [line for line in reader]\n",
    "\n",
    "with jsonlines.open(file2) as reader:\n",
    "    responses = [line for line in reader]\n",
    "\n",
    "request_ids = {request[\"custom_id\"] for request in requests}\n",
    "response_ids = {response[\"custom_id\"] for response in responses}\n",
    "\n",
    "missing_ids = request_ids - response_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_ids - request_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build The DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'custom_id': 'ADVE/86122854.jpg',\n",
       " 'response': {'body': {'choices': [{'content_filter_results': {'hate': {'filtered': False,\n",
       "       'severity': 'safe'},\n",
       "      'self_harm': {'filtered': False, 'severity': 'safe'},\n",
       "      'sexual': {'filtered': True, 'severity': 'medium'},\n",
       "      'violence': {'filtered': False, 'severity': 'safe'}},\n",
       "     'finish_reason': 'content_filter',\n",
       "     'index': 0,\n",
       "     'logprobs': None,\n",
       "     'message': {'refusal': None, 'role': 'assistant', 'content': ''}}],\n",
       "   'created': 1736052196,\n",
       "   'id': 'chatcmpl-AmCloQ7iMAMlyliJpH5MXg2mM2JL4',\n",
       "   'model': 'gpt-4o-2024-08-06',\n",
       "   'object': 'chat.completion',\n",
       "   'prompt_filter_results': [{'prompt_index': 0,\n",
       "     'content_filter_result': {'jailbreak': {'filtered': False,\n",
       "       'detected': False}}},\n",
       "    {'prompt_index': 1,\n",
       "     'content_filter_result': {'sexual': {'filtered': False,\n",
       "       'severity': 'safe'},\n",
       "      'violence': {'filtered': False, 'severity': 'safe'},\n",
       "      'hate': {'filtered': False, 'severity': 'safe'},\n",
       "      'self_harm': {'filtered': False, 'severity': 'safe'}}}],\n",
       "   'system_fingerprint': 'fp_f3927aa00d',\n",
       "   'usage': {'completion_tokens': 92,\n",
       "    'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "     'audio_tokens': 0,\n",
       "     'reasoning_tokens': 0,\n",
       "     'rejected_prediction_tokens': 0},\n",
       "    'prompt_tokens': 952,\n",
       "    'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0},\n",
       "    'total_tokens': 1044}},\n",
       "  'request_id': 'f5767183-1b76-4207-a158-e8a905c9eaed',\n",
       "  'status_code': 200},\n",
       " 'error': None}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_jsonl(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "# Load the JSONL files\n",
    "requests_data = read_jsonl(\"batch_requests_all.jsonl\")\n",
    "responses_data = read_jsonl(\"batch_responses_all.jsonl\")\n",
    "responses_data[245]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data from requests: 100%|██████████| 3476/3476 [00:00<00:00, 869529.47it/s]\n",
      "Extracting data from responses: 100%|██████████| 3476/3476 [00:00<00:00, 91025.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Filtered, Try to extract it again with Invoke\n",
      "Failed to extract text from ADVE/86122854.jpg\n",
      "Content Filtered, Try to extract it again with Invoke\n",
      "Failed to extract text from ADVE/87003967_87003968.jpg\n",
      "Content Filtered, Try to extract it again with Invoke\n",
      "Failed to extract text from Email/2072705831.jpg\n",
      "Content Filtered, Try to extract it again with Invoke\n",
      "Failed to extract text from Email/2064213091c.jpg\n",
      "Content Filtered, Try to extract it again with Invoke\n",
      "Failed to extract text from Email/2082564294a.jpg\n",
      "Content Filtered, Try to extract it again with Invoke\n",
      "Failed to extract text from Form/2501611413.jpg\n",
      "Content Filtered, Try to extract it again with Invoke\n",
      "Failed to extract text from Letter/502266196_502266198.jpg\n",
      "Content Filtered, Try to extract it again with Invoke\n",
      "Failed to extract text from Note/2072654561.jpg\n",
      "Content Filtered, Try to extract it again with Invoke\n",
      "Failed to extract text from scientific/2028716785.jpg\n",
      "Content Filtered, Try to extract it again with Invoke\n",
      "Failed to extract text from scientific/87592525_87592533.jpg\n",
      "Content Filtered, Try to extract it again with Invoke\n",
      "Failed to extract text from scientific/80231415_1417.jpg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>image_url</th>\n",
       "      <th>markdown_text</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resume/0000153377.jpg</td>\n",
       "      <td>https://filstrg.blob.core.windows.net/tobacco-...</td>\n",
       "      <td>## Fitzmaurice, Mary Anne\\n\\n### Research Biol...</td>\n",
       "      <td>\\nFitzmaurice, Mary Anne\\nResearch Biologist\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Resume/10036815_10036823.jpg</td>\n",
       "      <td>https://filstrg.blob.core.windows.net/tobacco-...</td>\n",
       "      <td># CURRICULUM VITAE\\n\\n## Name: \\nPeter M. Howl...</td>\n",
       "      <td>CURRICULUM VITAE\\n\\nName: Peter M. Howley, M.D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Resume/10087799_10087801.jpg</td>\n",
       "      <td>https://filstrg.blob.core.windows.net/tobacco-...</td>\n",
       "      <td>![Form No. 1a (For N.I.H. Continuation Grant a...</td>\n",
       "      <td>Form No. 1a (For N.I.H. Continuation Grant app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Resume/10150247_10150256.jpg</td>\n",
       "      <td>https://filstrg.blob.core.windows.net/tobacco-...</td>\n",
       "      <td>### UNIVERSITY OF MIAMI\\n\\n#### CURRICULUM VIT...</td>\n",
       "      <td>UNIVERSITY OF MIAMI\\n\\nCURRICULUM VITAE\\n\\nSta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Resume/11300115-0116.jpg</td>\n",
       "      <td>https://filstrg.blob.core.windows.net/tobacco-...</td>\n",
       "      <td># CURRICULUM VITAE\\n\\n## WILLIAM CARSON HINDS\\...</td>\n",
       "      <td>CURRICULUM VITAE\\n\\nWILLIAM CARSON HINDS\\n\\nBo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      custom_id  \\\n",
       "0         Resume/0000153377.jpg   \n",
       "1  Resume/10036815_10036823.jpg   \n",
       "2  Resume/10087799_10087801.jpg   \n",
       "3  Resume/10150247_10150256.jpg   \n",
       "4      Resume/11300115-0116.jpg   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://filstrg.blob.core.windows.net/tobacco-...   \n",
       "1  https://filstrg.blob.core.windows.net/tobacco-...   \n",
       "2  https://filstrg.blob.core.windows.net/tobacco-...   \n",
       "3  https://filstrg.blob.core.windows.net/tobacco-...   \n",
       "4  https://filstrg.blob.core.windows.net/tobacco-...   \n",
       "\n",
       "                                       markdown_text  \\\n",
       "0  ## Fitzmaurice, Mary Anne\\n\\n### Research Biol...   \n",
       "1  # CURRICULUM VITAE\\n\\n## Name: \\nPeter M. Howl...   \n",
       "2  ![Form No. 1a (For N.I.H. Continuation Grant a...   \n",
       "3  ### UNIVERSITY OF MIAMI\\n\\n#### CURRICULUM VIT...   \n",
       "4  # CURRICULUM VITAE\\n\\n## WILLIAM CARSON HINDS\\...   \n",
       "\n",
       "                                            raw_text  \n",
       "0  \\nFitzmaurice, Mary Anne\\nResearch Biologist\\n...  \n",
       "1  CURRICULUM VITAE\\n\\nName: Peter M. Howley, M.D...  \n",
       "2  Form No. 1a (For N.I.H. Continuation Grant app...  \n",
       "3  UNIVERSITY OF MIAMI\\n\\nCURRICULUM VITAE\\n\\nSta...  \n",
       "4  CURRICULUM VITAE\\n\\nWILLIAM CARSON HINDS\\n\\nBo...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# Function to read a JSONL file and return a list of dictionaries\n",
    "def read_jsonl(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "# Load the JSONL files\n",
    "requests_data = read_jsonl(\"batch_requests_all.jsonl\")\n",
    "responses_data = read_jsonl(\"batch_responses_all.jsonl\")\n",
    "\n",
    "# Create dictionaries to store the data\n",
    "requests_dict = {}\n",
    "responses_dict = {}\n",
    "\n",
    "# Extract data from the requests JSONL file\n",
    "for request in tqdm(requests_data, desc=\"Extracting data from requests\"):\n",
    "    custom_id = request[\"custom_id\"]\n",
    "    image_url = request[\"body\"][\"messages\"][1][\"content\"][1][\"image_url\"][\"url\"]\n",
    "    requests_dict[custom_id] = {\"image_url\": image_url}\n",
    "\n",
    "# Extract data from the responses JSONL file\n",
    "for response in tqdm(responses_data, desc=\"Extracting data from responses\"):\n",
    "    custom_id = response[\"custom_id\"]\n",
    "    try:\n",
    "        content = json.loads(response[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"])\n",
    "    except:\n",
    "        print(\"Content Filtered, Try to extract it again with Invoke\")\n",
    "        # Get the image url of that custom_id\n",
    "        image_url = requests_dict[custom_id][\"image_url\"]\n",
    "        # Invoke the function to extract the text\n",
    "        try:\n",
    "            content = ocr_invoke(system_prompt, user_prompt, image_url).dict()\n",
    "            print(f\"Extracted text from {custom_id}\")\n",
    "        except:\n",
    "            print(f\"Failed to extract text from {custom_id}\")\n",
    "            continue\n",
    "    markdown_text = content[\"markdown_text\"]\n",
    "    raw_text = content[\"raw_text\"]\n",
    "    responses_dict[custom_id] = {\"markdown_text\": markdown_text, \"raw_text\": raw_text}\n",
    "\n",
    "# Combine the data into a single list of dictionaries\n",
    "combined_data = []\n",
    "for custom_id, request_info in requests_dict.items():\n",
    "    if custom_id in responses_dict:\n",
    "        combined_data.append({\n",
    "            \"custom_id\": custom_id,\n",
    "            \"image_url\": request_info[\"image_url\"],\n",
    "            \"markdown_text\": responses_dict[custom_id][\"markdown_text\"],\n",
    "            \"raw_text\": responses_dict[custom_id][\"raw_text\"]\n",
    "        })\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(combined_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file (optional)\n",
    "df.to_csv(\"extracted_data.csv\", index=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.read_csv(\"extracted_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "Memo          620\n",
       "Email         596\n",
       "Letter        566\n",
       "Form          430\n",
       "Report        265\n",
       "scientific    258\n",
       "ADVE          222\n",
       "Note          200\n",
       "News          188\n",
       "Resume        120\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"class\"] = df[\"custom_id\"].apply(lambda x: x.split(\"/\")[0])\n",
    "df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>image_url</th>\n",
       "      <th>markdown_text</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resume/0000153377.jpg</td>\n",
       "      <td>https://filstrg.blob.core.windows.net/tobacco-...</td>\n",
       "      <td>## Fitzmaurice, Mary Anne\\n\\n### Research Biol...</td>\n",
       "      <td>\\nFitzmaurice, Mary Anne\\nResearch Biologist\\n...</td>\n",
       "      <td>Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Resume/10036815_10036823.jpg</td>\n",
       "      <td>https://filstrg.blob.core.windows.net/tobacco-...</td>\n",
       "      <td># CURRICULUM VITAE\\n\\n## Name: \\nPeter M. Howl...</td>\n",
       "      <td>CURRICULUM VITAE\\n\\nName: Peter M. Howley, M.D...</td>\n",
       "      <td>Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Resume/10087799_10087801.jpg</td>\n",
       "      <td>https://filstrg.blob.core.windows.net/tobacco-...</td>\n",
       "      <td>![Form No. 1a (For N.I.H. Continuation Grant a...</td>\n",
       "      <td>Form No. 1a (For N.I.H. Continuation Grant app...</td>\n",
       "      <td>Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Resume/10150247_10150256.jpg</td>\n",
       "      <td>https://filstrg.blob.core.windows.net/tobacco-...</td>\n",
       "      <td>### UNIVERSITY OF MIAMI\\n\\n#### CURRICULUM VIT...</td>\n",
       "      <td>UNIVERSITY OF MIAMI\\n\\nCURRICULUM VITAE\\n\\nSta...</td>\n",
       "      <td>Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Resume/11300115-0116.jpg</td>\n",
       "      <td>https://filstrg.blob.core.windows.net/tobacco-...</td>\n",
       "      <td># CURRICULUM VITAE\\n\\n## WILLIAM CARSON HINDS\\...</td>\n",
       "      <td>CURRICULUM VITAE\\n\\nWILLIAM CARSON HINDS\\n\\nBo...</td>\n",
       "      <td>Resume</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      custom_id  \\\n",
       "0         Resume/0000153377.jpg   \n",
       "1  Resume/10036815_10036823.jpg   \n",
       "2  Resume/10087799_10087801.jpg   \n",
       "3  Resume/10150247_10150256.jpg   \n",
       "4      Resume/11300115-0116.jpg   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://filstrg.blob.core.windows.net/tobacco-...   \n",
       "1  https://filstrg.blob.core.windows.net/tobacco-...   \n",
       "2  https://filstrg.blob.core.windows.net/tobacco-...   \n",
       "3  https://filstrg.blob.core.windows.net/tobacco-...   \n",
       "4  https://filstrg.blob.core.windows.net/tobacco-...   \n",
       "\n",
       "                                       markdown_text  \\\n",
       "0  ## Fitzmaurice, Mary Anne\\n\\n### Research Biol...   \n",
       "1  # CURRICULUM VITAE\\n\\n## Name: \\nPeter M. Howl...   \n",
       "2  ![Form No. 1a (For N.I.H. Continuation Grant a...   \n",
       "3  ### UNIVERSITY OF MIAMI\\n\\n#### CURRICULUM VIT...   \n",
       "4  # CURRICULUM VITAE\\n\\n## WILLIAM CARSON HINDS\\...   \n",
       "\n",
       "                                            raw_text   class  \n",
       "0  \\nFitzmaurice, Mary Anne\\nResearch Biologist\\n...  Resume  \n",
       "1  CURRICULUM VITAE\\n\\nName: Peter M. Howley, M.D...  Resume  \n",
       "2  Form No. 1a (For N.I.H. Continuation Grant app...  Resume  \n",
       "3  UNIVERSITY OF MIAMI\\n\\nCURRICULUM VITAE\\n\\nSta...  Resume  \n",
       "4  CURRICULUM VITAE\\n\\nWILLIAM CARSON HINDS\\n\\nBo...  Resume  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Embeddings from raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "co_embed = cohere.Client(\n",
    "    api_key=os.getenv(\"AZURE_ML_COHERE_EMBED_CREDENTIAL\"),\n",
    "    base_url=os.getenv(\"AZURE_ML_COHERE_EMBED_ENDPOINT\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the embedding\n",
    "docs = df.head()[\"raw_text\"].tolist()\n",
    "embeddings = co_embed.embed(\n",
    "    input_type=\"classification\",\n",
    "    texts=docs,\n",
    ").embeddings\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T07:17:45.403941Z",
     "start_time": "2025-01-05T07:17:45.390816Z"
    }
   },
   "outputs": [],
   "source": [
    "import aisuite as ai\n",
    "ai_client = ai.Client()\n",
    "ai_client.configure({\"azure\" : {\n",
    "  \"api_key\": os.environ[\"AZURE_API_KEY\"],\n",
    "  \"base_url\": os.environ[\"AZURE_BASE_URL\"]\n",
    "}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vlm_ocr(endpoint, model_deployment, system_prompt, user_prompt, url, key=\"1cd46458334d4daca5799b36aeec95d2\"):\n",
    "    vlm_client = ChatCompletionsClient(\n",
    "        endpoint=endpoint,\n",
    "        credential=AzureKeyCredential(key),\n",
    "        headers={\"azureml-model-deployment\": model_deployment},\n",
    "    )\n",
    "    response = vlm_client.complete(\n",
    "        messages=[\n",
    "            SystemMessage(content=system_prompt),\n",
    "            UserMessage(content=[\n",
    "                TextContentItem(text=user_prompt),\n",
    "                ImageContentItem(\n",
    "                    image_url=ImageUrl.load(\n",
    "                        image_file=url,\n",
    "                        image_format='jpg',\n",
    "                        detail=ImageDetailLevel.HIGH,\n",
    "                    )\n",
    "                )\n",
    "            ])\n",
    "        ],\n",
    "        model=model_deployment\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T08:08:26.341021Z",
     "start_time": "2025-01-05T08:08:24.214128Z"
    }
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "endpoint = \"https://archivai-ai-service.services.ai.azure.com/models\"\n",
    "deployment_name = \"Phi-3.5-vision-instruct\"\n",
    "url = \"https://filstrg.blob.core.windows.net/tobacco-dataset/ADVE/86122854.jpg\"\n",
    "\n",
    "system_prompt = \"Your are an OCR client using your Vision Capabilities to perform your response and provide a clean and structured text without any notes.\"\n",
    "\n",
    "vlm_user_prompt = \"\"\"extract the text from the image and provide a clean and structured text. \n",
    "                your output format must be in structred way format, with the text extracted from the image. \n",
    "                output will be  in 'markdown' text with markdown rules like titles,headings,etc, nothing else.\n",
    "                \n",
    "                NOTES:\n",
    "                1) in the output, don't write ```markdown``` or ```md``` or any other code block.\n",
    "                \n",
    "                2) don't add any notes from you, just out the text extracted from the image. without any additions\n",
    "                \n",
    "                3) Warning! Don't Add Notice section to tell me that the text is not clear or any other notes.\n",
    "\n",
    "                4) even if the text is not clear, try to extract as much as possible, and don't provide any extra notes.\n",
    "                \n",
    "                5) output the raw text extracted from the image as well. this text will be used for embedding purposes. So, Make sure that you don't lose any essential layouts when extract as raw text.\n",
    "                \n",
    "                6) Extract the text in the language it is written in the image.\n",
    "                                \n",
    "                7) Make the output in this format: text: <text extracted from the image>                \n",
    "                \"\"\"\n",
    "image_data = requests.get(url).content\n",
    "with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
    "    temp_file.write(image_data)\n",
    "    temp_file_path = temp_file.name\n",
    "response = vlm_ocr(endpoint, deployment_name, system_prompt, vlm_user_prompt, temp_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
