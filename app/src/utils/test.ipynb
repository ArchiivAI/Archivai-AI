{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd5fd119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Language</th>\n",
       "      <th>MarkdownText</th>\n",
       "      <th>RawText</th>\n",
       "      <th>FileId</th>\n",
       "      <th>VersionId</th>\n",
       "      <th>SearchVector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>english</td>\n",
       "      <td>### Key Partner\\n\\n- AI/ML platforms (e.g., Az...</td>\n",
       "      <td>Key Partner\\nAI/ML platforms (e.g., Azure ML)....</td>\n",
       "      <td>93</td>\n",
       "      <td>None</td>\n",
       "      <td>'acquisit':228 'activ':22 'advertis':131 'ai':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>english</td>\n",
       "      <td>### Key Partner  \\nAI/ML platforms (e.g., Azur...</td>\n",
       "      <td>Key Partner AI/ML platforms (e.g., Azure ML). ...</td>\n",
       "      <td>102</td>\n",
       "      <td>None</td>\n",
       "      <td>'acquisit':228 'activ':22 'advertis':131 'ai':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>english</td>\n",
       "      <td>### Sex Ratio of Bronchial Carcinoma\\n\\n(1969)...</td>\n",
       "      <td>SEX RATIO OF BRONCHIAL CARCINOMA\\n(1969) found...</td>\n",
       "      <td>110</td>\n",
       "      <td>None</td>\n",
       "      <td>'10':136 '15':62 '1959':64 '1963':218 '1969':6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73</td>\n",
       "      <td>english</td>\n",
       "      <td>Connect</td>\n",
       "      <td>Connect</td>\n",
       "      <td>111</td>\n",
       "      <td>None</td>\n",
       "      <td>'connect':1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77</td>\n",
       "      <td>english</td>\n",
       "      <td># Diagram Overview\\n\\n## Section\\n- Name: stri...</td>\n",
       "      <td>Diagram Overview\\n\\nSection\\n- Name: string\\n-...</td>\n",
       "      <td>118</td>\n",
       "      <td>None</td>\n",
       "      <td>'0':180 '1':173,182 '100':21 '10000000000':137...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id Language                                       MarkdownText  \\\n",
       "0  43  english  ### Key Partner\\n\\n- AI/ML platforms (e.g., Az...   \n",
       "1  66  english  ### Key Partner  \\nAI/ML platforms (e.g., Azur...   \n",
       "2  72  english  ### Sex Ratio of Bronchial Carcinoma\\n\\n(1969)...   \n",
       "3  73  english                                            Connect   \n",
       "4  77  english  # Diagram Overview\\n\\n## Section\\n- Name: stri...   \n",
       "\n",
       "                                             RawText  FileId VersionId  \\\n",
       "0  Key Partner\\nAI/ML platforms (e.g., Azure ML)....      93      None   \n",
       "1  Key Partner AI/ML platforms (e.g., Azure ML). ...     102      None   \n",
       "2  SEX RATIO OF BRONCHIAL CARCINOMA\\n(1969) found...     110      None   \n",
       "3                                            Connect     111      None   \n",
       "4  Diagram Overview\\n\\nSection\\n- Name: string\\n-...     118      None   \n",
       "\n",
       "                                        SearchVector  \n",
       "0  'acquisit':228 'activ':22 'advertis':131 'ai':...  \n",
       "1  'acquisit':228 'activ':22 'advertis':131 'ai':...  \n",
       "2  '10':136 '15':62 '1959':64 '1963':218 '1969':6...  \n",
       "3                                        'connect':1  \n",
       "4  '0':180 '1':173,182 '100':21 '10000000000':137...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the PostgreSQL database\n",
    "cnx = psycopg2.connect(user=\"archivai\", password=\"Saad@2356925\", host=\"archivai-database.postgres.database.azure.com\", port=5432, database=\"postgres\")\n",
    "print(\"Connected successfully!\")\n",
    "cur = cnx.cursor()\n",
    "query = \"\"\"SELECT * FROM public.\"Page\"\n",
    "            ORDER BY \"Id\" ASC\"\"\"\n",
    "cur.execute(query)\n",
    "rows = cur.fetchall()\n",
    "colnames = [desc[0] for desc in cur.description]\n",
    "df = pd.DataFrame(rows, columns=colnames)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "895f286d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Language', 'MarkdownText', 'RawText', 'FileId', 'VersionId',\n",
       "       'SearchVector'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db712544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "156fac69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['FileId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c22e3599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileId</th>\n",
       "      <th>RawText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93</td>\n",
       "      <td>Key Partner\\nAI/ML platforms (e.g., Azure ML)....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Key Partner AI/ML platforms (e.g., Azure ML). ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110</td>\n",
       "      <td>SEX RATIO OF BRONCHIAL CARCINOMA\\n(1969) found...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111</td>\n",
       "      <td>Connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118</td>\n",
       "      <td>Diagram Overview\\n\\nSection\\n- Name: string\\n-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FileId                                            RawText\n",
       "0      93  Key Partner\\nAI/ML platforms (e.g., Azure ML)....\n",
       "1     102  Key Partner AI/ML platforms (e.g., Azure ML). ...\n",
       "2     110  SEX RATIO OF BRONCHIAL CARCINOMA\\n(1969) found...\n",
       "3     111                                            Connect\n",
       "4     118  Diagram Overview\\n\\nSection\\n- Name: string\\n-..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df[['FileId', 'RawText']]\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50d85622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_content(df, file_id, file_id_col='FileId', raw_text_col='RawText'):\n",
    "    \"\"\"\n",
    "    Get concatenated content for a specific file ID\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame containing FileId and RawText columns\n",
    "    file_id: The file ID to get content for\n",
    "    file_id_col (str): Name of the FileId column\n",
    "    raw_text_col (str): Name of the RawText column\n",
    "    \n",
    "    Returns:\n",
    "    str: Concatenated raw text for the file ID\n",
    "    \"\"\"\n",
    "    file_data = df[df[file_id_col] == file_id]\n",
    "    if not file_data.empty:\n",
    "        return '\\n'.join(file_data[raw_text_col].astype(str))\n",
    "    else:\n",
    "        return f\"No content found for FileId: {file_id}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28e26bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files content and labels prepared.\n",
      "['Key Partner\\nAI/ML platforms (e.g., Azure ML).\\nCloud storage providers (e.g., Google Cloud, AWS).\\nMarketing & Distribution partners.\\nERP systems APIs.\\nKey Activities\\nProduct Development (Website and Mobile app).\\nDeveloping and training AI models for document classification.\\nContinuous improvement of the classification algorithm.\\nData management and privacy.\\nCustomer Support.\\nValue Proposition\\nAutomated document classification eliminates manual sorting and tagging.\\nAI-enhanced document querying makes finding information easier.\\nSimple and intuitive interface for offices and employees to manage their files.\\nScalability: Can handle increasing amounts of documents without the need for more manual work.\\nCustomer Relationships\\nCustomer Support: Providing setup assistance and ongoing help through live chat and email.\\nRegular updates: Providing new features, security patches, and improvements\\nPersonalized service: Option to customize the AI model for specific business needs\\nDigital Advertising Promoting through digital channels (Social Media)\\nCustomer Segments\\nB2B\\nMid-sized companies dealing with heavy document workloads, such as legal firms, healthcare providers, logistics companies, financial institutions, and real estate firms.\\nKey Resources\\nHuman Resources (Software engineers, AI Engineers, Customer support )\\nCloud infrastructure for document storage and AI processing\\nData for training the AI models (sample documents and file types)\\nFinancial Resources\\nChannels\\nMain Branches\\nCompany Website\\nMobile Application\\nSocial Media Platforms (e.g., LinkedIN)\\nCost Structure\\nAI/ML development and maintenance costs.\\nCloud infrastructure for document storage and processing and Hosting.\\nAPIs Costs.\\nMarketing and customer acquisition costs.\\nLegal and compliance costs (e.g., data privacy regulations).\\nRevenue Streams\\nSubscription models: Customers pay a monthly or yearly fee, with prices changing based on how many documents they handle each month\\nSupport and Maintenance', 'Key Partner AI/ML platforms (e.g., Azure ML). Cloud storage providers (e.g., Google Cloud, AWS). Marketing & Distribution partners. ERP systems APIs.\\n\\nKey Activities Product Development (Website and Mobile app). Developing and training AI models for document classification. Continuous improvement of the classification algorithm. Data management and privacy. Customer Support.\\n\\nValue Proposition Automated document classification eliminates manual sorting and tagging. AI-enhanced document querying makes finding information easier. Simple and intuitive interface for offices and employees to manage their files. Scalability: Can handle increasing amounts of documents without the need for more manual work.\\n\\nCustomer Relationships Customer Support: Providing setup assistance and ongoing help through live chat and email. Regular updates: Providing new features, security patches, and improvements Personalized service: Option to customize the AI model for specific business needs Digital Advertising: Promoting through digital channels (Social Media)\\n\\nCustomer Segments B2B Mid-sized companies dealing with heavy document workloads, such as legal firms, healthcare providers, logistics companies, financial institutions, and real estate firms.\\n\\nKey Resources Human Resources (Software engineers, AI Engineers, Customer support) Cloud infrastructure for document storage and AI processing Data for training the AI models (sample documents and file types) Financial Resources\\n\\nChannels Main Branches Company Website Mobile Application Social Media Platforms (e.g., LinkedIN)\\n\\nCost Structure AI/ML development and maintenance costs. Cloud infrastructure for document storage and processing and Hosting. APIs Costs. Marketing and customer acquisition costs. Legal and compliance costs (e.g., data privacy regulations).\\n\\nRevenue Streams Subscription models: Customers pay a monthly or yearly fee, with prices changing based on how many documents they handle each month Support and Maintenance', 'SEX RATIO OF BRONCHIAL CARCINOMA\\n(1969) found that adenocarcinoma was the commonest cell type in both men and women in both surgical and necropsy series. In series from Jamaica (Woo-  ding 1970) and Kampala (Templeton 1970) the proportions were 90% and 92% respectively. All these figures are very much higher than the proportion usual in the European countries, which vary around 15%.\\nKreyberg (1959) pointed out the relationship between the total incidence of bronchial carcinoma in any given country and the proportion of adeno- carcinomas reported: the lower the incidence the higher the proportion of adenocarcinomas, and these figures fit this observation. On the other hand, the total incidence of the disease has risen ten-fold in the last 30 years in Taiwan (Yang et al. 1969) and three-fold in the last 10 years in Japan. If the proportion of adenocarcinoma was solely related to the total incidence of the disease, then the proportion of this type of tumour should have fallen with the dramatic rise. It has not.\\nThe site of the tumours also seems to be different in the two parts of the world in that peripheral carcinomas account for over half the cases in the Far East as against a quarter in Europe (Yang et al. 1969; Ishikawa 1969; Lee & Tso 1963).\\nInsufficient data have been collected to make any firm statements about these aspects of bronchial carcinoma, but the evidence quoted suggests that a wider study in this field might also show a difference between the two parts of the world similar to that of the sex ratio.', 'Connect', 'Diagram Overview\\n\\nSection\\n- Name: string\\n- LastModified: DateTime\\n- Folders: List<Folder>\\n- Size: long\\n- FoldersCount: int\\n\\nRole\\n- Id: int\\n- Name: string (Unique, MaxLength=100)\\n- Permissions: List<Permission>\\n- Users: List<User>\\n\\nUser\\n- FirstName: string (Required, MaxLength=50)\\n- LastName: string (MaxLength=50)\\n- Email: string (Required, Email)\\n- PasswordHashed: string (Required)\\n- ImageUrl: string?\\n- Permissions: List<Permission>\\n- Roles: List<Role>\\n- Position: Position\\n\\nFolder\\n- Id: int\\n- SectionId: int?\\n- Name: string\\n- ParentFolderId: int?\\n- ParentFolder: Folder?\\n- CreateDate: DateTime\\n- LastModifiedDate: DateTime?\\n- CreateBy: int\\n- Metadata: JsonDocument\\n- SubFolders: List<Folder>\\n- Files: List<File>\\n- Size: long\\n- FilesCount: int\\n\\nFile\\n- Name: string\\n- FolderId: int\\n- UploadDate: DateTime\\n- LastModifiedDate: DateTime\\n- ModifiedVersion: int\\n- Size: long\\n- FileType: FileTypeEnum\\n- LockedBy: int?\\n- Path: string\\n- Metadata: json\\n\\nPermission\\n- ForEmail: string?\\n- RoleName: string\\n- Entity: Entity\\n- Action: FileAction\\n- FolderActions: List<FolderAction>\\n- SectionActions: List<SectionAction>\\n\\nOtp\\n- Id: int\\n- CreateDate: DateTime\\n- Links: List<File>\\n\\nDocStatics\\n- PdfCount: int\\n- WordCount: int\\n- ImageCount: int\\n- CsvCount: int\\n- Files: List<File>\\n- IncrementFoundFileType[type: FileTypeEnum]: int\\n\\nStorageUse\\n- TotalStorage: int = 10000000000\\n- IncrementStorage: int\\n- IncrementUsedStorage(pagesCount): int\\n\\nPage\\n- Id: int\\n- Language: string\\n- MarkdownText: string\\n- Next: int?\\n\\nVersion\\n- Id: int\\n- Name: string\\n- CreateDate: DateTime\\n- CreatedBy: int\\n- Description: string\\n- Page: Page\\n- Options: List<Attribute>\\n- Metadata: JsonDocument\\n\\nEnum Definitions\\n\\nPosition\\n- Owner = 1\\n- Manager = 2\\n- Employee = 3\\n\\nLanguages\\n- ar = 0\\n- en = 1\\n\\nFileTypeEnum\\n- Word\\n- Pdf\\n- Excel\\n- Image\\n- Csv\\n- Unknown\\n\\nEntity\\n- Section\\n- Folder\\n- File\\n\\nFileAction\\n- View\\n- Edit\\n- Delete\\n\\nFolderAction\\n- View\\n- Edit\\n- UploadFoldersOrFiles\\n- Delete\\n\\nSectionAction\\n- View\\n- Edit\\n- UploadFoldersOrFiles\\n- Delete']\n",
      "['93', '102', '110', '111', '118']\n"
     ]
    }
   ],
   "source": [
    "files_content = []\n",
    "lables = []\n",
    "for id in new_df['FileId'].unique():\n",
    "    content = get_file_content(new_df, id)\n",
    "    files_content.append(content)\n",
    "    lables.append(str(id))\n",
    "    \n",
    "print(\"Files content and labels prepared.\")\n",
    "print(files_content[:5])  # Display first 5 contents\n",
    "print(lables[:5])  # Display first 5 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9edd3fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Key Partner\\nAI/ML platforms (e.g., Azure ML).\\nCloud storage providers (e.g., Google Cloud, AWS).\\nMarketing & Distribution partners.\\nERP systems APIs.\\nKey Activities\\nProduct Development (Website and Mobile app).\\nDeveloping and training AI models for document classification.\\nContinuous improvement of the classification algorithm.\\nData management and privacy.\\nCustomer Support.\\nValue Proposition\\nAutomated document classification eliminates manual sorting and tagging.\\nAI-enhanced document querying makes finding information easier.\\nSimple and intuitive interface for offices and employees to manage their files.\\nScalability: Can handle increasing amounts of documents without the need for more manual work.\\nCustomer Relationships\\nCustomer Support: Providing setup assistance and ongoing help through live chat and email.\\nRegular updates: Providing new features, security patches, and improvements\\nPersonalized service: Option to customize the AI model for specific business needs\\nDigital Advertising Promoting through digital channels (Social Media)\\nCustomer Segments\\nB2B\\nMid-sized companies dealing with heavy document workloads, such as legal firms, healthcare providers, logistics companies, financial institutions, and real estate firms.\\nKey Resources\\nHuman Resources (Software engineers, AI Engineers, Customer support )\\nCloud infrastructure for document storage and AI processing\\nData for training the AI models (sample documents and file types)\\nFinancial Resources\\nChannels\\nMain Branches\\nCompany Website\\nMobile Application\\nSocial Media Platforms (e.g., LinkedIN)\\nCost Structure\\nAI/ML development and maintenance costs.\\nCloud infrastructure for document storage and processing and Hosting.\\nAPIs Costs.\\nMarketing and customer acquisition costs.\\nLegal and compliance costs (e.g., data privacy regulations).\\nRevenue Streams\\nSubscription models: Customers pay a monthly or yearly fee, with prices changing based on how many documents they handle each month\\nSupport and Maintenance',\n",
       " 'Key Partner AI/ML platforms (e.g., Azure ML). Cloud storage providers (e.g., Google Cloud, AWS). Marketing & Distribution partners. ERP systems APIs.\\n\\nKey Activities Product Development (Website and Mobile app). Developing and training AI models for document classification. Continuous improvement of the classification algorithm. Data management and privacy. Customer Support.\\n\\nValue Proposition Automated document classification eliminates manual sorting and tagging. AI-enhanced document querying makes finding information easier. Simple and intuitive interface for offices and employees to manage their files. Scalability: Can handle increasing amounts of documents without the need for more manual work.\\n\\nCustomer Relationships Customer Support: Providing setup assistance and ongoing help through live chat and email. Regular updates: Providing new features, security patches, and improvements Personalized service: Option to customize the AI model for specific business needs Digital Advertising: Promoting through digital channels (Social Media)\\n\\nCustomer Segments B2B Mid-sized companies dealing with heavy document workloads, such as legal firms, healthcare providers, logistics companies, financial institutions, and real estate firms.\\n\\nKey Resources Human Resources (Software engineers, AI Engineers, Customer support) Cloud infrastructure for document storage and AI processing Data for training the AI models (sample documents and file types) Financial Resources\\n\\nChannels Main Branches Company Website Mobile Application Social Media Platforms (e.g., LinkedIN)\\n\\nCost Structure AI/ML development and maintenance costs. Cloud infrastructure for document storage and processing and Hosting. APIs Costs. Marketing and customer acquisition costs. Legal and compliance costs (e.g., data privacy regulations).\\n\\nRevenue Streams Subscription models: Customers pay a monthly or yearly fee, with prices changing based on how many documents they handle each month Support and Maintenance',\n",
       " 'SEX RATIO OF BRONCHIAL CARCINOMA\\n(1969) found that adenocarcinoma was the commonest cell type in both men and women in both surgical and necropsy series. In series from Jamaica (Woo-  ding 1970) and Kampala (Templeton 1970) the proportions were 90% and 92% respectively. All these figures are very much higher than the proportion usual in the European countries, which vary around 15%.\\nKreyberg (1959) pointed out the relationship between the total incidence of bronchial carcinoma in any given country and the proportion of adeno- carcinomas reported: the lower the incidence the higher the proportion of adenocarcinomas, and these figures fit this observation. On the other hand, the total incidence of the disease has risen ten-fold in the last 30 years in Taiwan (Yang et al. 1969) and three-fold in the last 10 years in Japan. If the proportion of adenocarcinoma was solely related to the total incidence of the disease, then the proportion of this type of tumour should have fallen with the dramatic rise. It has not.\\nThe site of the tumours also seems to be different in the two parts of the world in that peripheral carcinomas account for over half the cases in the Far East as against a quarter in Europe (Yang et al. 1969; Ishikawa 1969; Lee & Tso 1963).\\nInsufficient data have been collected to make any firm statements about these aspects of bronchial carcinoma, but the evidence quoted suggests that a wider study in this field might also show a difference between the two parts of the world similar to that of the sex ratio.',\n",
       " 'Connect',\n",
       " 'Diagram Overview\\n\\nSection\\n- Name: string\\n- LastModified: DateTime\\n- Folders: List<Folder>\\n- Size: long\\n- FoldersCount: int\\n\\nRole\\n- Id: int\\n- Name: string (Unique, MaxLength=100)\\n- Permissions: List<Permission>\\n- Users: List<User>\\n\\nUser\\n- FirstName: string (Required, MaxLength=50)\\n- LastName: string (MaxLength=50)\\n- Email: string (Required, Email)\\n- PasswordHashed: string (Required)\\n- ImageUrl: string?\\n- Permissions: List<Permission>\\n- Roles: List<Role>\\n- Position: Position\\n\\nFolder\\n- Id: int\\n- SectionId: int?\\n- Name: string\\n- ParentFolderId: int?\\n- ParentFolder: Folder?\\n- CreateDate: DateTime\\n- LastModifiedDate: DateTime?\\n- CreateBy: int\\n- Metadata: JsonDocument\\n- SubFolders: List<Folder>\\n- Files: List<File>\\n- Size: long\\n- FilesCount: int\\n\\nFile\\n- Name: string\\n- FolderId: int\\n- UploadDate: DateTime\\n- LastModifiedDate: DateTime\\n- ModifiedVersion: int\\n- Size: long\\n- FileType: FileTypeEnum\\n- LockedBy: int?\\n- Path: string\\n- Metadata: json\\n\\nPermission\\n- ForEmail: string?\\n- RoleName: string\\n- Entity: Entity\\n- Action: FileAction\\n- FolderActions: List<FolderAction>\\n- SectionActions: List<SectionAction>\\n\\nOtp\\n- Id: int\\n- CreateDate: DateTime\\n- Links: List<File>\\n\\nDocStatics\\n- PdfCount: int\\n- WordCount: int\\n- ImageCount: int\\n- CsvCount: int\\n- Files: List<File>\\n- IncrementFoundFileType[type: FileTypeEnum]: int\\n\\nStorageUse\\n- TotalStorage: int = 10000000000\\n- IncrementStorage: int\\n- IncrementUsedStorage(pagesCount): int\\n\\nPage\\n- Id: int\\n- Language: string\\n- MarkdownText: string\\n- Next: int?\\n\\nVersion\\n- Id: int\\n- Name: string\\n- CreateDate: DateTime\\n- CreatedBy: int\\n- Description: string\\n- Page: Page\\n- Options: List<Attribute>\\n- Metadata: JsonDocument\\n\\nEnum Definitions\\n\\nPosition\\n- Owner = 1\\n- Manager = 2\\n- Employee = 3\\n\\nLanguages\\n- ar = 0\\n- en = 1\\n\\nFileTypeEnum\\n- Word\\n- Pdf\\n- Excel\\n- Image\\n- Csv\\n- Unknown\\n\\nEntity\\n- Section\\n- Folder\\n- File\\n\\nFileAction\\n- View\\n- Edit\\n- Delete\\n\\nFolderAction\\n- View\\n- Edit\\n- UploadFoldersOrFiles\\n- Delete\\n\\nSectionAction\\n- View\\n- Edit\\n- UploadFoldersOrFiles\\n- Delete',\n",
       " 'Searching for Documents Using AI\\n\\nEmployee/Manager\\n\\nEnter search query and submit\\n\\nWebsite\\n\\nSend search query to AI\\n\\nWeb Server\\n\\nAnalyze search query and find similar documents\\nReturn list of similar files\\n\\nAI\\n\\nDisplay search results',\n",
       " 'Company\\n\\nCompany Employee [Person]\\nView & Edit Documents\\n\\nCompany Owner [Person]\\nScans Documents\\n\\nCompany Customer [Person]\\nSend Emails with Documents\\n\\nScanner [API]\\nInterface\\n\\nGmail API [API]\\nFetches Documents from Emails\\n\\nEDMS\\n\\nText Classification LLM [AI Model]\\nClassify Text\\n\\nSQL Database [Database]\\nStores Files and Metadata\\n\\nFine-Tuning Module [Python Script]\\nMakes Periodic Fine-Tuning\\n\\nOCR [AI Model]\\nExtract Text from Docs\\n\\nEmbedding LLM [AI Model]\\nEmbed All Text\\n\\nVector Database [Database]\\nStores Text Embeddings\\n\\nBackend API [API]\\nInterface\\n\\nMobile Application [Android]\\nUser Interface\\n\\nWeb Application [Website]\\nUser Interface',\n",
       " \"Vending Operators\\nHere's more money for you!\\n\\nExtremely Narrow Vending Machines\\nViceroy Filter Tip\\nKool Filter\\nRaleigh\\nBelair\\n\\nNow these columns are WORTH $8 per machine per year to you in Fixed Compensation!\\n\\nThat's right! For bigger profits, here's the new BW payment schedule which now includes BELAIR—the light menthol cigarette with the famous Raleigh coupon. For each premium redeemed, here's how we'll pay you per machine per year under this new contract:\\n\\nViceroy, Kool Filter, Raleigh Filter, and Belair: $2.00\\nViceroy, Kool Filter and Raleigh Filter: $6.00\\nViceroy and Kool Filter: $4.00\\n\\nPlus BONUS PROFIT ON SALES!\\n\\nEvery carton of Raleigh and light menthol Belair cigarettes carries a bonus strip of 4 coupons—as shown above. Each strip is worth three cents in cash (or much more, if used for premiums) and this is key to more profits for you!\\n\\nN.B.: Additional Information, write Sales Dept.\\nAmerican Tobacco Murchandise Corporation\\nJob No. BW-904\\nGiven to American Tobacco Corporation and distributed to Vending Operators from February 15, 1955.\",\n",
       " 'Feature Describe Of The Feature DOKMEE DocuWare M-Files ArchivAI Folder Creation and Initial Setup The system lets users manually organize files, creating a structure for AI to learn from. Have this feature Have this feature Don’t have this feature Have this feature Automatic File Categorization with AI After setup, the AI automatically sorts new files based on content, eliminating manual organization. Don’t have this feature Don’t have this feature Have this feature Have this feature Semantic Search for Easy Document Retrieval We will implement semantic search to allow users to find documents by meaning, enhancing search speed and accuracy. Don’t have this feature Don’t have this feature Don’t have this feature Have this feature Text Extraction with OCR The system will use OCR to extract text from scanned documents, enabling searches for non-digital content. Have this feature Have this feature Have this feature Have this feature File Parsing and Metadata for Better Search Each document will be scanned for key details, saved as metadata, and used to simplify searches. Don’t have this feature Have this feature Have this feature Have this feature Testing and Feedback We will test the AI for accurate categorization and smooth searches, using user feedback to improve the system. Don’t have this feature Don’t have this feature Have this feature Have this feature Deployment and Ongoing Updates After testing, the system will be deployed for users, with continuous updates based on feedback and technological advancements. Have this feature Have this feature Have this feature Have this feature',\n",
       " 'Risk Event\\nResponse\\nContingency plan\\nTrigger\\n\\nSystem Downtime\\nRedundant servers, load balancing.\\nUse failover servers for quick recovery; escalate for long outages.\\nServer downtime alert.\\n\\nData loss\\nDaily backups, encrypted storage.\\nStore backups in secure cloud storage; test recovery regularly.\\nBackup failure or data corruption.\\n\\nAI Model Downtime or Malfunction\\nKeep a fallback model.\\nAutomatically switching to a previous checkpoint model.\\nAI model error.\\n\\nClassification Uncertainty\\nFlag low-confidence predictions for review.\\nUse manual review, retrain model.\\nConfidence score below threshold.\\n\\nSecurity Breach\\nHTTPS, encrypt data at rest.\\nRegular audits, enable multi-factor authentication, monitor for unusual access.\\nSuspicious activity alert.\\n\\nData Mismatch or Inconsistency\\nData validation checks.\\nSend alerts for inconsistencies; manual review as needed.\\nData mismatch detected.\\n\\nCommunication Failure\\nBackup communication channels (e.g., SMS).\\nTest backup alerts; ensure team is aware of alternatives.\\nPrimary communication failure.',\n",
       " 'Step into the future',\n",
       " 'AHMED',\n",
       " 'AHMAD',\n",
       " 'Step into the Future\\nNetworking\\nMentoring\\nTechnology Summit 2023\\nEmployment\\nPartner\\nMeska\\nExhibitor\\nCross Workers',\n",
       " 'ArchivAI\\n\\nAI Electronic Document Management System',\n",
       " 'Proposal for Documents Management and Classification using AI Project\\n\\n1- Proposal Index\\n\\n2. About Us .............................................................. Page 2\\n3. Problem Definition ......................................... Page 2\\n4. Motivation ............................................................ Page 3\\n5. Methodology ...................................................... Page 4\\n6. Risk Management ........................................... Page 5\\n7. Target Audience ............................................... Page 6\\n8. Timeline ................................................................ Page 7\\n9. Budget ................................................................... Page 7\\n10. Significance ...................................................... Page 8\\n11. Challenges .......................................................... Page 8\\n12. SW/HW Resources ......................................... Page 9\\n13. BMC (Business Model Canvas) ................ Page 9\\n2- About Us\\n\\nWe are a group of passionate and motivated students at Faculty of computer science at Mansoura University, united by our shared goal of using technology to make everyday tasks easier and more efficient. Our Graduation project, \"Documents Management and Classification using AI,\" is designed to help organizations manage their documents in a smarter way, using artificial intelligence to save time and reduce errors. We believe our system will transform how people handle their files, making it quicker and easier to find what they need.\\n\\nOur team is led by Amr Shoukry, who keeps everything on track with his leadership and vision. Each of us brings something unique to the table:\\n\\n1. Amr Shoukry: Frontend developer  \\n2. Ahmed Khaled: AI/ML developer  \\n3. Abdelrahman Karim: Mobile developer  \\n4. Alyaa Atef: AI/ML developer  \\n5. Nouran Elkhouly: UI/UX Designer  \\n6. Salma Ali: AI/ML developer  \\n7. Saad Al-Tohamy: AI/ML developer  \\n8. Shahd Faris: Backend developer  \\n9. Sohil Abuzeid: Backend developer  \\n10. Yomna Elsayed: UI/UX designer\\n\\nTogether, we\\'re excited to bring our project to life, combining our skills and teamwork to create something truly impactful.\\n\\n2- Problem Definition\\n\\nManaging documents manually is increasingly challenging as organizations handle growing volumes of files each day. Employees spend considerable time searching for documents, organizing them into appropriate folders, and ensuring everything is up-to-date. This not only slows down operations but also causes delays in decision-making, sometimes leading to significant business setbacks when critical documents are misplaced or hard to find. Traditional document management systems fail to keep pace with the increasing file volumes or the rapid changes in business needs, often lacking in areas like compliance and security. With the advent of advanced technologies such as artificial intelligence and machine learning, there is a compelling need for a smarter system that can automate document organization to store all previous documents in easy way, enhance search capabilities, and manage data more effectively, thereby improving efficiency and reducing human error.\\nMotivation\\n\\nAI is transforming industries: Artificial intelligence is changing the way industries work by automating tasks that were previously done manually, making processes faster and more efficient.\\n\\nManual document management is outdated: Many government agencies and companies still rely on old-fashioned manual systems to manage files, which slows down operations and makes it difficult to find important documents when needed.\\n\\nChallenges in government agencies: People often struggle to locate old or misplaced documents, like family records, in government offices. This process can take a lot of time due to poor organization of physical documents.\\n\\nRisk of damage to physical documents: Paper documents are fragile and can be easily damaged or lost over time, making it harder to keep records safe for the future.\\n\\nAI can save time and money: Automating the way we organize and retrieve documents using AI could save a lot of time, effort, and resources that are currently wasted on manual processes.\\n\\nBetter access and preservation: An AI-powered system would not only organize documents more efficiently but also ensure they\\'re easily accessible and well-preserved for long-term use, which benefits both agencies and the public.\\n\\nSmarter search with semantic search: By using semantic search, the system would understand the meaning behind a search, not just match keywords. This means users will get more accurate and relevant results, even if they don’t use the exact search terms, making it easier to find what they need quickly.\\n4- Methodology\\n\\n- Folder Creation and Initial Setup:\\nThe system will start by allowing users to create folders and manually upload their initial documents. This gives the user control over how their files are organized at the beginning, setting up a structure that the AI can learn from.\\n\\n- Automatic File Categorization with AI:\\nOnce the initial setup is done, the AI will automatically take over. Any new files that come in will be analyzed and placed into the appropriate folder based on their content. Users won’t need to worry about organizing new files manually—the system will handle it for them, saving time and effort.\\n\\n- Semantic Search for Easy Document Retrieval:\\nWe will implement semantic search so that users can search for documents based on meaning rather than just keywords. This makes searching faster and more accurate, even if the user doesn’t know the exact name or content of the file they’re looking for.\\n\\n- Text Extraction with OCR:\\nTo make documents searchable, especially scanned or image-based ones, the system will use Optical Character Recognition (OCR) to extract text from them. This will allow users to search through the content of even non-digital documents.\\n\\n- File Parsing and Metadata for Better Search:\\nEach document will be scanned to pull out important details like names, dates, or other key information. This data will be saved as metadata alongside the document, making it easier for users to search for files using simple terms like a person’s name or other relevant details.\\n\\n- Testing and Feedback:\\nWe’ll run thorough tests to make sure the AI accurately categorizes files and that the search function works smoothly. User feedback will be essential for refining the system and ensuring it’s user-friendly and reliable.\\n\\n- Deployment and Ongoing Updates:\\nAfter testing, the system will be deployed and made available to users. We’ll continue to provide updates and make improvements based on user input and advances in technology to ensure the system stays efficient and effective.\\n5- Risk Management\\n\\nRisk: AI Misclassifying Documents\\n\\nOne of the risks in using AI for document management is that the system might sometimes place documents in the wrong folder. This could lead to confusion, making it harder to find important files. Misclassification can occur if the AI doesn’t fully understand the content of a document, especially when documents are complex or similar to each other. Since AI models are not perfect, it’s essential to have ways to catch and fix these mistakes.\\n\\nSolutions to Address Misclassification:\\n\\nHuman Review and Feedback:\\nTo tackle this, the system should allow users to review and correct any misclassifications. If a document ends up in the wrong place, users can easily move it to the right folder and provide feedback to the AI. This way, the system can learn from its mistakes and become more accurate over time.\\n\\nConfidence Scores:\\nThe AI can assign a confidence score to each classification decision. If the system is unsure about where a document should go, it can flag that document for user review. For example, if the AI only has 60% confidence that a document belongs in a certain folder, it can ask the user to double-check before finalizing the decision.\\n\\nRetraining the AI:\\nAI needs to learn and improve over time. Regularly retraining the system using new data, especially with examples of corrected classifications, will help reduce misclassifications. This ongoing learning process ensures the AI stays up-to-date and accurate.\\n6- Target Audience\\n\\n- Government Agencies:\\nGovernment offices that manage large volumes of physical and digital documents can benefit from this system to streamline their file management, reduce manual work, and improve document retrieval processes.\\n\\n- Large Organizations:\\nCompanies that deal with extensive documentation—such as legal firms, healthcare providers, and financial institutions—can use this system to manage sensitive documents efficiently and improve compliance with data storage regulations.\\n\\n- Educational Institutions:\\nSchools, universities, and research institutions often manage vast archives of student records, research papers, and administrative documents. The AI-powered system would help organize and quickly retrieve such files.\\n\\n- Healthcare Providers:\\nClinics and hospitals that handle patient records, medical histories, and insurance documents could benefit from automated document management and search functions, improving the speed and accuracy of administrative tasks.\\n\\n- Law Firms:\\nLegal professionals handling contracts, case files, and other critical documents can use the system to efficiently store and retrieve case-related files while ensuring confidentiality.\\n\\n- Libraries and Archives:\\nLibraries and public archives managing historical or rare documents could use the system to digitize and preserve their collections, while making them easily searchable for researchers.\\n\\n- SMEs (Small and Medium Enterprises):\\nSmall and medium-sized businesses that manage operational documents, client files, and contracts can use the system to simplify document organization and retrieval without investing in a large-scale solution.\\n\\n- Individuals or Freelancers:\\nIndividuals who manage a personal archive of documents—like legal records, financial statements, or creative work—could also benefit from an automated system that helps keep their files organized\\n5- Timeline\\n\\nSprint Focus and Deliverables\\n\\nSprint 1-2 Focus: Planning, gathering requirements, and initial system design. Deliverables: Basic UI for folder creation and document upload.\\n\\nSprint 3-4 Focus: Develop folder creation and document upload features. Deliverables: Functional folder management and file upload features.\\n\\nSprint 5-6 Focus: Implement AI for document classification (early version). Deliverables: Basic AI model integrated into the system with initial testing.\\n\\nSprint 7-8 Focus: Develop OCR functionality and semantic search. Deliverables: OCR to extract text from documents, searchable content.\\n\\nSprint 9-10 Focus: Testing, fixing bugs, and refining AI model based on feedback. Deliverables: Improved AI model accuracy and semantic search testing.\\n\\nSprint 11-12 Focus: User testing and feedback, system refinement. Deliverables: Iterations based on user feedback, UI/UX improvements.\\n\\nSprint 13-14 Focus: Final adjustments and preparing for deployment. Deliverables: Fully functional system ready for final deployment.\\n\\nSprint 15 Focus: Final deployment and post-launch support. Deliverables: Deployed system, user documentation, ongoing updates.\\n\\n6- Budget\\n\\nTo ensure the smooth and efficient running of our AI-powered document management system, we will need to invest in both servers and GPUs. The servers will host the document management system, databases, and AI models, providing the backbone for data processing and storage. We plan to either purchase high-performance on-premise servers or use cloud-based services, depending on cost-effectiveness and scalability. Cloud options such as AWS, Google Cloud, or Microsoft Azure offer flexibility, with monthly costs based on usage, while on-premise servers would require an upfront investment but offer more control over data security.\\n\\nFor the AI model training and processing tasks, we will need to acquire powerful GPUs. These will handle the computationally intensive work of training our models and processing large datasets efficiently. Options include high-performance GPUs like NVIDIA Tesla or AMD equivalents, which are designed for machine learning tasks.\\n7- Significance\\n\\n• Saves Time: The system will automatically organize and sort documents, saving employees time that would otherwise be spent doing these tasks manually.\\n• Increases Accuracy: AI reduces errors in document classification, making it easier to find the right files when needed.\\n• Handles Growth: The system will grow with the organization, easily managing more documents and new types of files over time.\\n• Better Search: With advanced search powered by AI, users can quickly find the documents they need by using simple, everyday language.\\n• Ensures Compliance: Automatically tagging and tracking documents helps meet legal and regulatory requirements without the need for manual checks.\\n• Cuts Costs: By reducing manual tasks, the system lets employees focus on more important work, improving productivity and reducing operational costs.\\n• Learns and Adapts: The AI will keep learning from users, getting better at sorting and finding documents as time goes on.\\n\\n8- Challenges\\n\\n• Quality and Availability of Data: Finding and maintaining high-quality data for training AI models is crucial. The system\\'s effectiveness depends heavily on the quality and relevance of the data used.\\n• Complex AI Training: The process of designing and training AI models to classify and sort various document types can be intricate. These models must handle diverse formats and complexities without errors.\\n• Integration Hurdles: Integrating the new system with existing IT infrastructure poses significant challenges, from ensuring compatibility to managing data migration and minimizing operational disruptions.\\n• User Adoption: Getting users to switch to a new system and alter their document handling habits requires effective training and change management strategies to ensure smooth adoption.\\n• Privacy and Security: Managing sensitive documents means stringent security measures are essential to comply with laws.\\n• Scalability and Maintenance: The system must scale with the growing amount of data and users and requires continuous maintenance to keep up with technological advancements and security demands. \\n- Budget Management: Development costs can escalate quickly due to unexpected technical challenges, potentially leading to budget overruns.\\n\\n9- SW/HW Resources\\n\\n- Servers:\\n  - Purpose: To host the document management system, databases, and AI models.\\n  - Type: On-premise servers or cloud-based servers (AWS, Google Cloud, Azure).\\n\\n- Storage Systems:\\n  - Purpose: To store large volumes of data securely.\\n  - Type: High-capacity hard drives, SSDs, or cloud storage solutions.\\n\\n- GPUs:\\n  - Purpose: For training AI models and processing large datasets.\\n  - Examples: NVIDIA Tesla, AMD Radeon Pro.\\n\\n10- BMC (Business Model Canvas)\\n\\n- Key Partners\\n  - AI/ML platforms (e.g., TensorFlow, PyTorch)\\n  - Cloud providers (e.g., Google Cloud, AWS)\\n  - Document management systems\\n  - Universities or research institutions for developing advanced AI models\\n  - Local offices, law firms, government archives, and businesses (early adopters)\\n\\n- Key Activities\\n  - Developing and training AI models for document classification and search\\n  - Continuous improvement of algorithms\\n  - User interface and experience design for ease of use in querying and searching\\n  - Marketing and user acquisition (targeting businesses, archives, libraries)\\n  - Customer support and onboarding for using the system\\n  - Data management and privacy setups\\n\\n- Key Resources\\n  - AI/ML expertise for developing classification algorithms\\n  - Software developers for building the application and integration\\n  - Cloud infrastructure for document storage and AI processing\\n  - Data for training the AI models (sample documents of all file types)\\n  - Financial resources for development, marketing, and operations\\n\\n- Value Propositions\\n  - Time-saving: Automated document classification eliminates manual sorting and tagging\\n  - Increased accuracy: AI ensures that documents are placed in the correct folders\\n  - Improved search functionality: AI-enhanced document querying makes finding information easier\\n  - User-friendly: Simple interface for admins and employees to manage their files\\n  - Scalability: Can handle increasing amounts of documents without the need for more manual work\\n\\n- Customer Relationships\\n  - Onboarding support: Initial setup assistance and training for office users\\n  - Technical support: Continuous assistance through live chat, email, or phone\\n  - Regular updates: Providing new features, security patches, and improvements\\n  - Personalized service: Options to customize the system model for specific business needs\\n\\n- Channels\\n  - Direct sales: Engaging offices, archives, and document-heavy industries directly\\n  - Online marketing: Promoting through digital channels (website, social media, webinars)\\n  - Strategic partnerships: Selling document management consulting\\n  - Trade shows and industry conferences: To demonstrate the app to potential customers\\n\\n- Customer Segments\\n  - Small and medium-sized offices with high document processing needs (e.g., law firms, medical offices, educational institutions)\\n  - Large organizations (e.g., government archives, corporate offices, libraries)\\n  - Companies in need of improved document search and organization features\\n\\n- Cost Structure\\n  - AI/ML development and maintenance costs\\n  - Cloud infrastructure for document storage and processing\\n  - Salaries for developers, AI specialists, and support staff\\n  - Marketing and customer acquisition costs\\n  - Legal and compliance costs (e.g., data privacy regulations)\\n\\n- Revenue Streams\\n  - Subscription model: Charging customers a monthly or yearly fee based on usage (e.g., per number of documents or storage volume)\\n  - Tiered pricing: Offering different plans based on the size of the business (e.g., small offices vs. large enterprises)\\n  - Customization fees: Charging for specialized integrations or custom AI models\\n  - Consulting services: Offering AI and document management consulting']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "835174cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Add the project root to Python path\n",
    "sys.path.append('D:\\Archivai-AI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282ea0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import os\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from app.src.utils.classifier import TextClassifier\n",
    "from app.src.utils.trainer import Trainer\n",
    "from typing import List\n",
    "from app.src.utils.config import encoder_path\n",
    "import numpy as np\n",
    "\n",
    "def get_file_content(df, file_id, file_id_col='FileId', raw_text_col='RawText'):\n",
    "    \"\"\"\n",
    "    Get concatenated content for a specific file ID\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame containing FileId and RawText columns\n",
    "    file_id: The file ID to get content for\n",
    "    file_id_col (str): Name of the FileId column\n",
    "    raw_text_col (str): Name of the RawText column\n",
    "    \n",
    "    Returns:\n",
    "    str: Concatenated raw text for the file ID\n",
    "    \"\"\"\n",
    "    file_data = df[df[file_id_col] == file_id]\n",
    "    if not file_data.empty:\n",
    "        return '\\n'.join(file_data[raw_text_col].astype(str))\n",
    "    else:\n",
    "        return f\"No content found for FileId: {file_id}\"\n",
    "\n",
    "def train_model(chere_client: cohere.Client):\n",
    "    # Connect to the PostgreSQL database\n",
    "    cnx = psycopg2.connect(user=\"archivai\", password=\"Saad@2356925\", host=\"archivai-database.postgres.database.azure.com\", port=5432, database=\"postgres\")\n",
    "    print(\"Connected successfully!\")\n",
    "    cur = cnx.cursor()\n",
    "    query = \"\"\"SELECT * FROM public.\"Page\"\n",
    "                ORDER BY \"Id\" ASC\"\"\"\n",
    "    cur.execute(query)\n",
    "    rows = cur.fetchall()\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    df = pd.DataFrame(rows, columns=colnames)\n",
    "\n",
    "    # Slicing the DataFrame to get only FileId and RawText columns\n",
    "    df_sliced = df[['FileId', 'RawText']]\n",
    "\n",
    "    # Getting the content for each file\n",
    "    files_content = []\n",
    "    lables = []\n",
    "    for id in new_df['FileId'].unique():\n",
    "        content = get_file_content(df_sliced, id)\n",
    "        files_content.append(content)\n",
    "        lables.append(str(id))\n",
    "    \n",
    "    # get the embeddings\n",
    "    raw_text = files_content\n",
    "    embeddings = chere_client.embed(input_type= 'classification', texts= raw_text).embeddings\n",
    "\n",
    "    # encoding the target variable \n",
    "    encoder = LabelEncoder()\n",
    "    labels_encoded = encoder.fit_transform(lables)\n",
    "\n",
    "    # Save the trained encoder\n",
    "    joblib.dump(encoder, encoder_path)\n",
    "\n",
    "    # converting to torch tensor\n",
    "    embeddings_tensor = torch.tensor(embeddings, dtype=torch.float32)\n",
    "    labels_tensor = torch.tensor(labels_encoded)\n",
    "\n",
    "    # splitting the data to train and test\n",
    "    embeddings_train, embeddings_test, classes_train, classes_test = train_test_split(\n",
    "                embeddings_tensor, labels_tensor, test_size=0.20, random_state=0)\n",
    "    \n",
    "    # Create TensorDataset\n",
    "    train_dataset = TensorDataset(embeddings_train, classes_train)\n",
    "    test_dataset = TensorDataset(embeddings_test, classes_test)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    batch_size = 32  \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "    # inistantiating a model\n",
    "    model = TextClassifier(num_classes = len(labels))\n",
    "\n",
    "    # choosing device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # calculating counts\n",
    "    class_counts = np.bincount(labels_encoded)\n",
    "    weights = 1.0 / torch.tensor(class_counts, dtype=torch.float32)\n",
    "    weights = weights / weights.sum()\n",
    "\n",
    "    # setting the criterion, optimizer and schedular\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=weights.to(device))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "    # training and validating the model\n",
    "    trainer_inist = Trainer(model, criterion, optimizer, scheduler, device)\n",
    "    trainer_inist.train(train_loader, test_loader, num_epochs=30, patience= 5)\n",
    "\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2cc5c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\laptop\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30]\n",
      "Training - Loss: 3.0006, Accuracy: 8.33%\n",
      "Validation - Loss: 2.8019, Accuracy: 0.00%\n",
      "Epoch [2/30]\n",
      "Training - Loss: 2.3371, Accuracy: 41.67%\n",
      "Validation - Loss: 2.8049, Accuracy: 0.00%\n",
      "Epoch [3/30]\n",
      "Training - Loss: 2.7797, Accuracy: 16.67%\n",
      "Validation - Loss: 2.8114, Accuracy: 0.00%\n",
      "Epoch [4/30]\n",
      "Training - Loss: 2.5068, Accuracy: 8.33%\n",
      "Validation - Loss: 2.8152, Accuracy: 0.00%\n",
      "Epoch [5/30]\n",
      "Training - Loss: 2.2438, Accuracy: 41.67%\n",
      "Validation - Loss: 2.8192, Accuracy: 0.00%\n",
      "Epoch [6/30]\n",
      "Training - Loss: 2.1993, Accuracy: 25.00%\n",
      "Validation - Loss: 2.8199, Accuracy: 0.00%\n",
      "Early stopping triggered!\n"
     ]
    }
   ],
   "source": [
    "#from app.src.utils.building_model import train_model\n",
    "\n",
    "# Train the model with the prepared data\n",
    "train_model(raw_text=files_content, labels=lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6725a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
